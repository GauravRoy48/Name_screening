{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Screening\n",
    "\n",
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "1. [Function Definitions](#func-defs)\n",
    "    1. [Name Screening Solutions](#first-func-def)\n",
    "    2. [Plot - Execution Speed](#second-func-def)\n",
    "    3. [Plot - Number of matches & Execution Time](#third-func-def)\n",
    "    4. [Plot - Accuracy](#fourth-func-def)\n",
    "    5. [Metric Comparision for final distance metric](#fifth-func-def)\n",
    "    6. [Threshold Analysis for finalizing thresholds](#sixth-func-def)\n",
    "2. [Load data](#load-data)\n",
    "3. [Data Analysis](#data-analysis)\n",
    "    1. [Generate test data](#gen-test)\n",
    "    2. [Find optimal thresholds](#find-thresholds)\n",
    "        1. [Finding metrics](#find-thresholds-part1)\n",
    "        2. [Finding Lower Limit of thresholds](#find-thresholds-part2)\n",
    "        3. [Finding Upper Limit of thresholds](#find-thresholds-part3)\n",
    "    3. [Finding Optimal Solution](#find-solution)\n",
    "4. [Generate performance plots](#gen-plots)\n",
    "    1. [Using True positives](#sec_4_1)\n",
    "    2. [Using False positives](#sec_4_2)\n",
    "5. [Compare performance with name list without the randomly generated names](#alt-find-solution)\n",
    "    1. [Loading data source and test set](#sec_5_1)\n",
    "    2. [Finding best solution using true positive](#sec_5_2)\n",
    "    3. [Finding best solution using false positive](#sec_5_3)\n",
    "    4. [Generate performance plots](#sec_5_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(\"Python Version:\", python_version())\n",
    "\n",
    "import matplotlib\n",
    "print(\"Matplotlib Version:\", matplotlib. __version__) \n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(action='once')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pip install abydos\n",
    "# pip install python-Levenshtein\n",
    "\n",
    "\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from abydos import phonetic, distance\n",
    "from Levenshtein import ratio as lev_ratio\n",
    "from Levenshtein import seqratio as lev_seqratio\n",
    "from Levenshtein import setratio as lev_setratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Function Definitions <a class=\"anchor\" id=\"func-defs\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Function Definition - All name screening solutions <a class=\"anchor\" id=\"first-func-def\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)\n",
    "\n",
    "The function provided **FIVE** options. They are as follows:\n",
    "1. Applying Levenshtein set ratio on the names directly ***(Traditional approach)***\n",
    "2. Applying Levenshtein set ratio on the phonemes of the names\n",
    "3. Using custom Levenshtein ratio to measure similarity between the phonemes of the names\n",
    "4. Using BOTH Levenshtein set ratio on names AND custom Levenshtein ratio on phonemes of the names for comparision ***(Proposed approach 1)***\n",
    "5. Using EITHER Levenshtein set ratio on names OR custom Levenshtein ratio on phonemes of the names for comparision ***(Proposed approach 2)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Ideal model using true positive records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solutions(sol_type, db, func, thres, name, actual_name, enable_prints=True):\n",
    "    \n",
    "    print()\n",
    "    sol_name = \"\"\n",
    "    if sol_type == 1:\n",
    "        print('Solution 1 - Levenshtein set ratio on name matching')\n",
    "        sol_name = \"Baseline Solution\"\n",
    "    elif sol_type == 2:\n",
    "        print('Solution 2 - Levenshtein set ratio on Phoneme matching')\n",
    "        sol_name = \"Intermediate Solution 1\"\n",
    "    elif sol_type == 3:\n",
    "        print('Solution 3 - Custom Levenshtein Ratio on Phonemes')\n",
    "        sol_name = \"Intermediate Solution 2\"\n",
    "    elif sol_type == 4:\n",
    "        print('Solution 4 - Levenshtein set ratio AND Custom Levenshtein Ratio on Phonemes')\n",
    "        sol_name = \"Proposed Solution 1\"\n",
    "    elif sol_type == 5:\n",
    "        print('Solution 5 - Levenshtein set ratio OR Custom Levenshtein Ratio on Phonemes')\n",
    "        sol_name = \"Proposed Solution 2\"\n",
    "    else:\n",
    "        print('Invalid Option! Choose from 1 to 5')\n",
    "        return None\n",
    "    \n",
    "    print('Searched Name:', name, '\\nActual Name:', actual_name)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    start_time= time.time()\n",
    "    \n",
    "    if sol_type != 1:\n",
    "        pn = []\n",
    "        for t in name.split():\n",
    "            pn.append(phonetic.DoubleMetaphone().encode(t)[0])\n",
    "            \n",
    "        if enable_prints:\n",
    "            print(f\"Phoneme for {name} is : {pn}\")\n",
    "    \n",
    "    for row in db.iterrows():\n",
    "        \n",
    "        if sol_type == 1:\n",
    "            metric = func(row[1]['Name'].lower(), name.lower())\n",
    "        elif sol_type == 2:\n",
    "            metric = func(' '.join(row[1]['Phonemes']).lower(), ' '.join(pn).lower())\n",
    "        elif sol_type == 3:\n",
    "            dist_score = []\n",
    "            dist_score = [max([(func(i,j)) for j in row[1]['Phonemes']]) for i in pn]\n",
    "            metric = np.mean(dist_score)\n",
    "        elif sol_type == 4 or sol_type == 5:\n",
    "            metric1 = func[0](row[1]['Name'].lower(), name.lower())\n",
    "            dist_score = []\n",
    "            dist_score = [max([(func[1](i,j)) for j in row[1]['Phonemes']]) for i in pn]\n",
    "            metric2 = np.mean(dist_score)\n",
    "        \n",
    "        if sol_type == 1 or sol_type == 2 or sol_type == 3:\n",
    "            condition = (metric >= thres)\n",
    "        elif sol_type == 4:\n",
    "            condition = (metric1 >= thres[0] and metric2 >= thres[1])\n",
    "        elif sol_type == 5:\n",
    "            condition = (metric1 >= thres[0] or metric2 >= thres[1])\n",
    "\n",
    "        \n",
    "        if condition:\n",
    "            \n",
    "            if sol_type == 1:\n",
    "                dist = np.round(lev_ratio(row[1]['Name'].lower(), name.lower()), 2)\n",
    "            elif sol_type == 2:\n",
    "                dist = np.round(lev_ratio(' '.join(row[1]['Phonemes']).lower(), ' '.join(pn).lower()), 2)\n",
    "            \n",
    "            if sol_type == 1 or sol_type == 2:\n",
    "                df2 = {'Name': row[1]['Name'], \n",
    "                       'LevSetRatio': metric, \n",
    "                       'Distance': dist}\n",
    "            elif sol_type == 3:\n",
    "                df2 = {'Name': row[1]['Name'], \n",
    "                       'Phoneme': row[1]['Phonemes'], \n",
    "                       'LevRatio': metric}\n",
    "            elif sol_type == 4 or sol_type == 5:\n",
    "                df2 = {'Name': row[1]['Name'], \n",
    "                       'Phoneme': row[1]['Phonemes'], \n",
    "                       'LevSetRatio': metric1, \n",
    "                       'LevRatio': metric2}\n",
    "\n",
    "            results = results.append(df2, ignore_index = True)\n",
    "\n",
    "    fin_time = np.round((time.time() - start_time), 2)\n",
    "    print(f\"--- Execution Time: {fin_time:,} seconds ---\")\n",
    "    \n",
    "    if sol_type == 1 or sol_type == 2:\n",
    "        if not results.empty:\n",
    "            results.sort_values('LevSetRatio', ascending=False, inplace=True)\n",
    "    elif sol_type == 3:\n",
    "        if not results.empty:\n",
    "            results.sort_values('LevRatio', ascending=False, inplace=True)\n",
    "    elif sol_type == 4 or sol_type == 5:\n",
    "        if not results.empty:\n",
    "            results.sort_values(['LevRatio', 'LevSetRatio'], ascending=False, inplace=True)\n",
    "    \n",
    "    results.reset_index(drop=True, inplace=True)\n",
    "    if enable_prints:\n",
    "        print(\"Number of matched names:\", results.shape[0])\n",
    "    \n",
    "    actual_present = False\n",
    "    if not results.empty:\n",
    "        if results[results.Name.str.contains(actual_name)].shape[0]:\n",
    "            actual_present = True\n",
    "            if enable_prints:\n",
    "                print('Results contain the actual name!')\n",
    "                display(results[results.Name.str.contains(actual_name)])\n",
    "        else:\n",
    "            actual_present = False\n",
    "            if enable_prints:\n",
    "                print('Results do not contain the actual name...')\n",
    "\n",
    "    return sol_name, results, actual_present, fin_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Ideal model using false positive records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solutions2(sol_type, db, func, thres, name, enable_prints=True):\n",
    "    \n",
    "    print()\n",
    "    sol_name = \"\"\n",
    "    if sol_type == 1:\n",
    "        print('Solution 1 - Levenshtein set ratio on name matching')\n",
    "        sol_name = \"Baseline Solution\"\n",
    "    elif sol_type == 2:\n",
    "        print('Solution 2 - Levenshtein set ratio on Phoneme matching')\n",
    "        sol_name = \"Intermediate Solution 1\"\n",
    "    elif sol_type == 3:\n",
    "        print('Solution 3 - Custom Levenshtein Ratio on Phonemes')\n",
    "        sol_name = \"Intermediate Solution 2\"\n",
    "    elif sol_type == 4:\n",
    "        print('Solution 4 - Levenshtein set ratio AND Custom Levenshtein Ratio on Phonemes')\n",
    "        sol_name = \"Proposed Solution 1\"\n",
    "    elif sol_type == 5:\n",
    "        print('Solution 5 - Levenshtein set ratio OR Custom Levenshtein Ratio on Phonemes')\n",
    "        sol_name = \"Proposed Solution 2\"\n",
    "    else:\n",
    "        print('Invalid Option! Choose from 1 to 5')\n",
    "        return None\n",
    "    \n",
    "    print('Searched Name:', name)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    start_time= time.time()\n",
    "    \n",
    "    if sol_type != 1:\n",
    "        pn = []\n",
    "        for t in name.split():\n",
    "            pn.append(phonetic.DoubleMetaphone().encode(t)[0])\n",
    "            \n",
    "        if enable_prints:\n",
    "            print(f\"Phoneme for {name} is : {pn}\")\n",
    "    \n",
    "    for row in db.iterrows():\n",
    "        \n",
    "        if sol_type == 1:\n",
    "            metric = func(row[1]['Name'].lower(), name.lower())\n",
    "        elif sol_type == 2:\n",
    "            metric = func(' '.join(row[1]['Phonemes']).lower(), ' '.join(pn).lower())\n",
    "        elif sol_type == 3:\n",
    "            dist_score = []\n",
    "            dist_score = [max([(func(i,j)) for j in row[1]['Phonemes']]) for i in pn]\n",
    "            metric = np.mean(dist_score)\n",
    "        elif sol_type == 4 or sol_type == 5:\n",
    "            metric1 = func[0](row[1]['Name'].lower(), name.lower())\n",
    "            dist_score = []\n",
    "            dist_score = [max([(func[1](i,j)) for j in row[1]['Phonemes']]) for i in pn]\n",
    "            metric2 = np.mean(dist_score)\n",
    "        \n",
    "        if sol_type == 1 or sol_type == 2 or sol_type == 3:\n",
    "            condition = (metric >= thres)\n",
    "        elif sol_type == 4:\n",
    "            condition = (metric1 >= thres[0] and metric2 >= thres[1])\n",
    "        elif sol_type == 5:\n",
    "            condition = (metric1 >= thres[0] or metric2 >= thres[1])\n",
    "\n",
    "        \n",
    "        if condition:\n",
    "            \n",
    "            if sol_type == 1:\n",
    "                dist = np.round(lev_ratio(row[1]['Name'].lower(), name.lower()), 2)\n",
    "            elif sol_type == 2:\n",
    "                dist = np.round(lev_ratio(' '.join(row[1]['Phonemes']).lower(), ' '.join(pn).lower()), 2)\n",
    "            \n",
    "            if sol_type == 1 or sol_type == 2:\n",
    "                df2 = {'Name': row[1]['Name'], \n",
    "                       'LevSetRatio': metric, \n",
    "                       'Distance': dist}\n",
    "            elif sol_type == 3:\n",
    "                df2 = {'Name': row[1]['Name'], \n",
    "                       'Phoneme': row[1]['Phonemes'], \n",
    "                       'LevRatio': metric}\n",
    "            elif sol_type == 4 or sol_type == 5:\n",
    "                df2 = {'Name': row[1]['Name'], \n",
    "                       'Phoneme': row[1]['Phonemes'], \n",
    "                       'LevSetRatio': metric1, \n",
    "                       'LevRatio': metric2}\n",
    "\n",
    "            results = results.append(df2, ignore_index = True)\n",
    "\n",
    "    fin_time = np.round((time.time() - start_time), 2)\n",
    "    print(f\"--- Execution Time: {fin_time:,} seconds ---\")\n",
    "    \n",
    "    if sol_type == 1 or sol_type == 2:\n",
    "        if not results.empty:\n",
    "            results.sort_values('LevSetRatio', ascending=False, inplace=True)\n",
    "    elif sol_type == 3:\n",
    "        if not results.empty:\n",
    "            results.sort_values('LevRatio', ascending=False, inplace=True)\n",
    "    elif sol_type == 4 or sol_type == 5:\n",
    "        if not results.empty:\n",
    "            results.sort_values(['LevRatio', 'LevSetRatio'], ascending=False, inplace=True)\n",
    "    \n",
    "    results.reset_index(drop=True, inplace=True)\n",
    "    if enable_prints:\n",
    "        print(\"Number of matched names:\", results.shape[0])\n",
    "\n",
    "\n",
    "    return sol_name, results, fin_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Function Definition - Plot horizonal bar for comparing execution speed <a class=\"anchor\" id=\"second-func-def\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_exec_speed(results, searched_name, actual_name):\n",
    "    fig, ax = plt.subplots(figsize=(10,3))\n",
    "\n",
    "    sols = [val[0] for val in results]\n",
    "    times = [val[3] for val in results]\n",
    "    perc_change = [\" \"+str(np.round((val-times[0])*100/times[0], 2))+\" %\" for val in times]\n",
    "    bar_colors = ['green' if val[2] else 'red' for val in results]\n",
    "\n",
    "\n",
    "    ax.barh(sols, times, color=bar_colors)\n",
    "\n",
    "    for index, val in enumerate(times):\n",
    "        plt.text(val, index, val, \n",
    "                 color = 'black', horizontalalignment='left', verticalalignment='center')\n",
    "        if index == 0:\n",
    "            continue\n",
    "        plt.text(val, index, perc_change[index], \n",
    "                 color = 'white', horizontalalignment='right', verticalalignment='center')\n",
    "\n",
    "    ax.set_yticklabels(sols)\n",
    "\n",
    "    # Labels are inverted by default\n",
    "    ax.invert_yaxis()  \n",
    "\n",
    "    ax.set_xlabel('Fetch time (seconds)')\n",
    "    ax.set_title(f'Execution speed while searching for \"{actual_name}\" using \"{searched_name}\" ')\n",
    "    plt.grid(True, axis = 'x')\n",
    "\n",
    "\n",
    "    green_patch = mpatches.Patch(color='green', label='Name matched')\n",
    "    red_patch = mpatches.Patch(color='red', label='Name not matched')\n",
    "    ax.legend(handles=[green_patch, red_patch])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Function Definition - Plot merged bar and line plot to compare number of false positive matches <a class=\"anchor\" id=\"third-func-def\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_performance_plots(df, focal_entity , limits, xlabels, figsize):\n",
    "    ax1 = sns.set_style(style=None, rc=None )\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=figsize)\n",
    "\n",
    "    g = sns.lineplot(data = df['Time'], marker='o', sort = False, ax=ax1, label=\"Execution Time\")\n",
    "    g.set(ylim=limits[0])\n",
    "    ax2 = ax1.twinx()\n",
    "    for index, row in df.iterrows():\n",
    "        g.text(row.name, \n",
    "                   row['Time'], \n",
    "                   np.round(row['Time'], 2), \n",
    "                   color='black', \n",
    "                   ha=\"center\", \n",
    "                   size='large', \n",
    "                   verticalalignment='bottom')\n",
    "\n",
    "    bplot = sns.barplot(data = df, x=focal_entity, y='Num_of_matches', alpha=0.5, ax=ax2, label=\"Number of matches\")\n",
    "    bplot.set(ylim=limits[1])\n",
    "    for index, row in df.iterrows():\n",
    "        bplot.text(row.name, \n",
    "                   row['Num_of_matches'], \n",
    "                   int(row['Num_of_matches']), \n",
    "                   color='black', \n",
    "                   ha=\"center\", \n",
    "                   size='large', \n",
    "                   verticalalignment='baseline')\n",
    "\n",
    "    #ax1.set_xticklabels(df[focal_entity], rotation=90)\n",
    "    #ax1.set_xlabel(xlabels)\n",
    "    ax1.set_xlabel('Solutions')\n",
    "    ax1.set_ylabel('Execution Time (seconds)')\n",
    "    ax2.set_ylabel('Number of matches')\n",
    "    plt.title('Comparing Number of matches and Execution speed among different solutions')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Function Definition - Plot bar plot of accuracy of each model <a class=\"anchor\" id=\"fourth-func-def\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_TP_perc_plot(df, focal_entity, ylims, figsize):\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    g = sns.barplot(data = df, x=focal_entity, y='Name_found', alpha=0.5)\n",
    "    for index, row in df.iterrows():\n",
    "        g.text(row.name, \n",
    "                   row['Name_found'], \n",
    "                   np.round(row['Name_found'], 2), \n",
    "                   color='black', \n",
    "                   ha=\"center\", \n",
    "                   size='large', \n",
    "                   verticalalignment='baseline')\n",
    "    g.set_xlabel('Solutions')\n",
    "    g.set_ylabel('Percentage of SENSITIVITY (%)')\n",
    "    g.set(ylim=ylims)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.title('Percentage of Sensitivity (TPR)')\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Function Definition - Metric analysis for phonemes and names <a class=\"anchor\" id=\"fifth-func-def\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric analysis for phoneme matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_analysis1(maindb, tests):\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    for test in tests:\n",
    "        \n",
    "        actual_name = test[0]\n",
    "        \n",
    "        for name in test[1]:\n",
    "            #print()\n",
    "            #print('Searched Name:', name, '\\nActual Name:', actual_name)\n",
    "\n",
    "            pn = []\n",
    "            for t in name.split():\n",
    "                pn.append(phonetic.DoubleMetaphone().encode(t)[0])\n",
    "\n",
    "            #print(f\"Phoneme for {name} is : {pn}\")\n",
    "            \n",
    "\n",
    "            db = maindb[maindb.Name.str.contains(actual_name)]\n",
    "            for row in db.iterrows():\n",
    "\n",
    "\n",
    "                dist_score = []\n",
    "                metric0 = lev_ratio(' '.join(row[1]['Phonemes']).lower(), ' '.join(pn).lower())\n",
    "                dist_score = [max([(lev_ratio(i,j)) for j in row[1]['Phonemes']]) for i in pn]\n",
    "                metric1 = np.mean(dist_score)\n",
    "                metric2 = lev_seqratio(row[1]['Phonemes'], pn)\n",
    "                metric3 = lev_setratio(row[1]['Phonemes'], pn)\n",
    "                #print([name, , , metric2])\n",
    "\n",
    "\n",
    "                df2 = {'Name': row[1]['Name'],\n",
    "                       'Searched': name, \n",
    "                       #'Actual': actual_name, \n",
    "                       'Phoneme': row[1]['Phonemes'], \n",
    "                       'Searched Phoneme': pn, \n",
    "                       'Levenshtein Ratio': metric0, \n",
    "                       'Custom Levenshtein Ratio': metric1, \n",
    "                       'Levenshtein Seq Ratio': metric2, \n",
    "                       'Levenshtein Set Ratio': metric3}\n",
    "\n",
    "                results = results.append(df2, ignore_index = True)\n",
    "\n",
    "\n",
    "    results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric analysis for name matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_analysis2(maindb, tests):\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    for test in tests:\n",
    "        \n",
    "        actual_name = test[0]\n",
    "        \n",
    "        for name in test[1]:\n",
    "            #print()\n",
    "            #print('Searched Name:', name, '\\nActual Name:', actual_name)\n",
    "\n",
    "            pn = []\n",
    "            for t in name.split():\n",
    "                pn.append(phonetic.DoubleMetaphone().encode(t)[0])\n",
    "\n",
    "            #print(f\"Phoneme for {name} is : {pn}\")\n",
    "            \n",
    "\n",
    "            db = maindb[maindb.Name.str.contains(actual_name)]\n",
    "            for row in db.iterrows():\n",
    "\n",
    "\n",
    "                metric0 = lev_ratio(row[1]['Name'].lower(), name.lower())\n",
    "                metric1 = np.mean([max([(lev_ratio(i,j)) for j in name.lower().split()]) for i in row[1]['Name'].lower().split()])\n",
    "                metric2 = lev_seqratio(row[1]['Name'].lower(), name.lower())\n",
    "                metric3 = lev_setratio(row[1]['Name'].lower(), name.lower())\n",
    "\n",
    "\n",
    "                df2 = {'Name': row[1]['Name'],\n",
    "                       'Searched': name, \n",
    "                       #'Actual': actual_name, \n",
    "                       'Phoneme': row[1]['Phonemes'], \n",
    "                       'Searched Phoneme': pn, \n",
    "                       'Lev Ratio': metric0, \n",
    "                       'Custom Lev Ratio': metric1, \n",
    "                       'Lev Seq Ratio': metric2, \n",
    "                       'Lev Set Ratio': metric3}\n",
    "\n",
    "                results = results.append(df2, ignore_index = True)\n",
    "\n",
    "\n",
    "    results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Function Definition - Threshold finalization for phonemes and names metrics <a class=\"anchor\" id=\"sixth-func-def\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower Limit using True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thres_analysis(maindb, tests):\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    for test in tests:\n",
    "        \n",
    "        actual_name = test[0]\n",
    "        \n",
    "        for name in test[1]:\n",
    "            #print()\n",
    "            #print('Searched Name:', name, '\\nActual Name:', actual_name)\n",
    "\n",
    "            pn = []\n",
    "            for t in name.split():\n",
    "                pn.append(phonetic.DoubleMetaphone().encode(t)[0])\n",
    "\n",
    "            #print(f\"Phoneme for {name} is : {pn}\")\n",
    "            \n",
    "\n",
    "            db = maindb[maindb.Name.str.contains(actual_name)]\n",
    "            for row in db.iterrows():\n",
    "\n",
    "\n",
    "                #metric1 = func[0](row[1]['Name'].lower(), name.lower())\n",
    "                metric1 = lev_setratio(row[1]['Name'].lower(), name.lower())\n",
    "                metric2 = np.mean([max([(lev_ratio(i,j)) for j in name.lower().split()]) for i in row[1]['Name'].lower().split()])\n",
    "                dist_score = []\n",
    "                #dist_score = [max([(func[1](i,j)) for j in row[1]['Phonemes']]) for i in pn]\n",
    "                #metric2 = func[1](row[1]['Name'].lower(), name.lower())\n",
    "                #print([name, lev_seqratio(row[1]['Phonemes'], pn), lev_setratio(row[1]['Phonemes'], pn), metric2])\n",
    "\n",
    "\n",
    "                df2 = {'Name': row[1]['Name'],\n",
    "                       'Searched': name, \n",
    "                       #'Actual': actual_name, \n",
    "                       'Phoneme': row[1]['Phonemes'], \n",
    "                       'Searched Phoneme': pn,                         \n",
    "                       'Lev Set Ratio': metric1, \n",
    "                       'Custom Lev Ratio': metric2}\n",
    "\n",
    "                results = results.append(df2, ignore_index = True)\n",
    "\n",
    "\n",
    "    results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper Limit using False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thres_analysis_unknown(flag, maindb, func, tests):\n",
    "\n",
    "    perc = np.arange(0,0.9, 0.1)\n",
    "    perc2 = np.arange(0.9, 1, 0.05)\n",
    "    perc = np.concatenate([perc, perc2])\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    consolidated_results = pd.DataFrame()\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    name_counter = 1\n",
    "    for name in tests[-1][1]:\n",
    "\n",
    "        pn = []\n",
    "        for t in name.split():\n",
    "            pn.append(phonetic.DoubleMetaphone().encode(t)[0])\n",
    "\n",
    "        db = maindb\n",
    "        print(name_counter, name)\n",
    "        counter = 0\n",
    "        for row in db.iterrows():\n",
    "\n",
    "            metric1 = None\n",
    "            metric2 = None\n",
    "            if flag == 1:\n",
    "                metric1 = func[0](row[1]['Name'].lower(), name.lower())\n",
    "            elif flag==2:\n",
    "                dist_score = [max([(func[1](i,j)) for j in row[1]['Phonemes']]) for i in pn]\n",
    "                metric2 = np.mean(dist_score)\n",
    "                \n",
    "            counter += 1\n",
    "            if counter%5000 == 0:\n",
    "                print(counter)\n",
    "            df2 = {'Lev Set Ratio': (metric1), \n",
    "                   'Custom Lev Ratio': (metric2)}\n",
    "\n",
    "            results = results.append(df2, ignore_index = True)\n",
    "                    \n",
    "        \n",
    "        cdf = results.describe(percentiles=perc).T\n",
    "        display(cdf)\n",
    "        consolidated_results = consolidated_results.append(cdf, ignore_index = True)\n",
    "        results = pd.DataFrame()\n",
    "\n",
    "        name_counter +=1\n",
    "        \n",
    "    \n",
    "    print(f'Execution Time: {time.time()-start_time:,} seconds')\n",
    "    results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return results, consolidated_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data <a class=\"anchor\" id=\"load-data\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_pickle('Final_Names_w_Random.pkl')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.groupby('List').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysis <a class=\"anchor\" id=\"data-analysis\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Generate test data <a class=\"anchor\" id=\"gen-test\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names.iloc[np.random.randint(names.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [[\"Vladimir Nikolaevich Terentev\", [\"Vadimir Nikolevi Terente\", \n",
    "                                            \"Valdimi Terente\", \n",
    "                                            \"Baldimi Nikola Terete\", \n",
    "                                            \"Wadimi Terente\", \n",
    "                                            \"Baldimir Derend\"]], \n",
    "         [\"Andrey Alshevskih\", [\"andre alshveck\", \n",
    "                                \"andrew alshvek\", \n",
    "                                \"andy alshevsik\", \n",
    "                                \"andy alsevsikh\", \n",
    "                                \"Aandre Alshweshk\"]],\n",
    "         [\"Andrei Skoch\", [\"andrew skok\", \n",
    "                           \"andre skokh\", \n",
    "                           \"andrai skosh\", \n",
    "                           \"Aandre kock\", \n",
    "                           \"Andres kok\"]], \n",
    "         [\"Sheikh Aboud Rogo\", [\"Shake Abud rogo\", \n",
    "                                \"Sheik abod roguo\", \n",
    "                                \"about roguo\", \n",
    "                                \"shaikh rogo\", \n",
    "                                \"Shek Abed Rogo\"]], \n",
    "         [\"Mohammad Fayez Al-Barsha\", [\"Mohamad Fayis Barsa\", \n",
    "                                       \"Fayes Barhsa\", \n",
    "                                       \"Mohamed Al barsha\", \n",
    "                                       \"Moamad faes albasha\", \n",
    "                                       \"mohamad fayiz\"]], \n",
    "         [\"Wael Mohamad ABED AL RAHMAAN\", [\"Wel Mohammad ABID RAHMAN\", \n",
    "                                           \"Wael AL-HUSSEINI\", \n",
    "                                           \"Wel Huseni\", \n",
    "                                           \"Mohammad Rehman\", \n",
    "                                           \"Vial Abed\"]], \n",
    "         [\"Khaled Suleiman Fayez ABOU HASSAN\", [\"Khalid Sulayman Fayiz ABU HASAN\", \n",
    "                                                \"Khaled ABU HASSAN\", \n",
    "                                                \"Kahleed Asan\", \n",
    "                                                \"Kohlid Faye Hasin\", \n",
    "                                                \"Galed Hassan\"]], \n",
    "         [\"David Amos Mazengo\", [\"Dave Masengo\", \n",
    "                                 \"Daveid Mos Masingo\", \n",
    "                                 \"Dave Masego\", \n",
    "                                 \"Daive Masego\", \n",
    "                                 \"Davie Mos Masigo\"]], \n",
    "         [\"Anas Tals\", [\"Annas Taals\", \n",
    "                        \"Unus Tuls\", \n",
    "                        \"Aanas Daals\", \n",
    "                        \"Aanas Thaals\", \n",
    "                        \"Aunaas Dhals\"]], \n",
    "         [\"Fares Chihabi\", [\"Faresh Chiabi\", \n",
    "                            \"Farez Chivi\", \n",
    "                            \"Faresh Jiavi\", \n",
    "                            \"Farsh Jiabi\", \n",
    "                            \"Vares Jabi\"]], \n",
    "         [\"Henni Ziegert\", [\"Heni Zigart\", \n",
    "                            \"Heini Zegart\", \n",
    "                            \"Heini Cigart\", \n",
    "                            \"Haini Cigat\", \n",
    "                            \"Henny Zigat\"]], \n",
    "         [\"Ebony Macdonald\", [\"Abony Mcdonald\", \n",
    "                                 \"Albany Macdonall\", \n",
    "                                 \"Ebboni Mactonalt\", \n",
    "                                 \"Ebni Donald\", \n",
    "                                 \"Abby Mctonal\"]], \n",
    "         [\"Joseph Barton\", [\"Josef Baurtan\", \n",
    "                            \"Josev Boltan\", \n",
    "                            \"Joseph Balton\", \n",
    "                            \"Josh Borton\", \n",
    "                            \"josaif bolton\"]], \n",
    "         [\"Octavia Gracia Crespo Cantero\", [\"Octave Cresbo Candaro\", \n",
    "                                            \"Octavia Cantaro\", \n",
    "                                            \"Garcia Cantaro\", \n",
    "                                            \"Auktabia Creshpho Cantaro\", \n",
    "                                            \"Ockdawia Garcia\"]], \n",
    "         [\"Kimberly Williams\", [\"Kimmerly Wiliam\", \n",
    "                                \"Gimmarly William\", \n",
    "                                \"Kimmerli Wilams\", \n",
    "                                \"Kimmaly Villams\", \n",
    "                                \"Kinderli Vilians\"]], \n",
    "         [\"Robert Tapia\", [\"Rupert Dapia\", \n",
    "                           \"Robby Topia\", \n",
    "                           \"Rob Thapi\", \n",
    "                           \"Robet Daphia\", \n",
    "                           \"Rupat Darpa\"]], \n",
    "         [\"Blanca Chamorro\", [\"Blanka Chamoro\", \n",
    "                                  \"Blanga Jamoro\", \n",
    "                                  \"Bianca Chmore\", \n",
    "                                  \"Vlanga Jmore\", \n",
    "                                  \"Balanca Janore\"]], \n",
    "         [\"Eliana Ferreras Coello\", [\"Alina phereras collo\", \n",
    "                                  \"Elaina Goel\", \n",
    "                                  \"Elena fererash Goel\", \n",
    "                                  \"elyana phereros colo\", \n",
    "                                  \"vereros goelo\"]], \n",
    "         [\"Camilla Parini-Correr\", [\"Camila Perni COuraire\", \n",
    "                                    \"Cammila Gorere\", \n",
    "                                    \"Gamla Barrinni\", \n",
    "                                    \"Camela Goryere\", \n",
    "                                    \"Camiya Barreni Gouryer\"]],\n",
    "         [\"Paola Tropea\", [\"Pola Tropio\", \n",
    "                          \"Baola Tropia\", \n",
    "                          \"Powla Tropica\", \n",
    "                          \"Poula Drobiya\", \n",
    "                          \"Paula Dobia\"]], \n",
    "         [\"Piergiorgio Gentili\", [\"Pejergio Gentili\", \n",
    "                                \"Pergorgio Jentily\", \n",
    "                                \"Pejerjio Jenely\", \n",
    "                                \"Paijhogio Gently\", \n",
    "                                \"Piyejorgio Jentali\"]], \n",
    "         [\"DUMMY DATA\", [\"Antonio Hodge\", \n",
    "                         \"Charles Madriz\", \n",
    "                         \"Aleh Vladimir Aziz\", \n",
    "                         \"Luke Powell\", \n",
    "                         \"Anthony Gammell\", \n",
    "                         \"Carlos Vilches\", \n",
    "                         \"Mike Felix\", \n",
    "                         \"Rodrigue Patterson\", \n",
    "                         \"Anya D'Souza\", \n",
    "                         \"Joshua Matthers\", \n",
    "                         \"Michael Myers\", \n",
    "                         \"Owen Price\", \n",
    "                         \"Christopher Peres\", \n",
    "                         \"Mark Gibney\", \n",
    "                         \"Andrew Roy\", \n",
    "                         \"Jared Miller\", \n",
    "                         \"Scott Romero\", \n",
    "                         \"Alex Owen\", \n",
    "                         \"Steve Leben\", \n",
    "                         \"Kirk Jensen\", \n",
    "                         \"Kevin Berry\", \n",
    "                         \"Mike King\", \n",
    "                         \"Mark Bruno\", \n",
    "                         \"Tony Hayes\", \n",
    "                         \"Kevin Sanchez\", \n",
    "                         \"Bill Miller\", \n",
    "                         \"Bob Turner\", \n",
    "                         \"James Wilson\", \n",
    "                         \"Matt Smith\", \n",
    "                         \"Ted Blair\", \n",
    "                         \"Eric Dalton\", \n",
    "                         \"Lynn Davis\", \n",
    "                         \"Dennis Joseph\", \n",
    "                         \"Andrew Ford\", \n",
    "                         \"Douglas Williams\", \n",
    "                         \"Lee Davidson\", \n",
    "                         \"Henry Cohen\", \n",
    "                         \"Carl Jacobs\", \n",
    "                         \"Terry Martinez\", \n",
    "                         \"Joshua Davis\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if part of name is present in data - Ideally, YES\n",
    "names[names.Name.str.contains('Davis')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if entire name is present - Ideally, NO\n",
    "for nm in tests[-1][1]:\n",
    "    print(names[names.Name.str.contains(nm)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Find the optimal thresholds <a class=\"anchor\" id=\"find-thresholds\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Find the metrics <a class=\"anchor\" id=\"find-thresholds-part1\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Abydos and python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abydos - Distance\n",
    "stat_time = time.time()\n",
    "for test in tests:\n",
    "    for i in test[1]:\n",
    "        (distance.dist_levenshtein(test[0], i))\n",
    "print(f'Abydos Execution Speed: {np.round((time.time()-stat_time)*1000, 4)} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein \n",
    "stat_time = time.time()\n",
    "for test in tests:\n",
    "    for val in test[1]:\n",
    "        (lev_ratio(test[0], val))\n",
    "print(f'python-Levenshtein Execution Speed: {np.round((time.time()-stat_time)*1000, 4)} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find metric for phoneme matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = np.arange(0,1, 0.1)\n",
    "res = metric_analysis1(names, tests)\n",
    "display(res.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find metric for name matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = np.arange(0,1, 0.1)\n",
    "\n",
    "res = metric_analysis2(names, tests)\n",
    "display(res.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, it is visible that the best metrics are as follows:\n",
    "- Best name comparision metric : **Levenshtein Set Ratio**\n",
    "- Best phoneme comparision metric : **Custom Levenshtein ratio**\n",
    "\n",
    "Therefore, using these to finalize the thresholds for the metric..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Find the Lower Limit using True Positive data <a class=\"anchor\" id=\"find-thresholds-part2\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = thres_analysis(names, tests)\n",
    "\n",
    "#res.sort_values(['Lev Set Ratio'])\n",
    "#res[res['Lev Set Ratio']<0.75]\n",
    "#res.sort_values(['Custom Lev Ratio'])\n",
    "#res[res['Custom Lev Ratio']<60]\n",
    "perc1 = np.arange(0,0.1, 0.05)\n",
    "perc2 = np.arange(0.1, 1, 0.1)\n",
    "perc = np.concatenate([perc1, perc2])\n",
    "display(res.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the observations, to catch the variations, it is best to set the thresholds at 5% as follows:\n",
    "- Levenshtein Set Ratio = **0.535** *(for name matching)*\n",
    "- Custom Levenshtein ratio = **0.514** *(for phoneme matching)*\n",
    "\n",
    "The next stage looks at increasing the limits, for reducing the false positives as much as possible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Find the Upper Limit using False Positive data <a class=\"anchor\" id=\"find-thresholds-part3\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func = [lev_setratio, lev_ratio]\n",
    "#threshs = [0.368, 0.4]\n",
    "\n",
    "perc = np.arange(0,1, 0.1)\n",
    "\n",
    "\n",
    "res1, cres1 = thres_analysis_unknown(1, names, func, tests)\n",
    "#display(res1.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cres1.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = np.arange(0,0.9, 0.1)\n",
    "perc2 = np.arange(0.9, 1, 0.05)\n",
    "perc = np.concatenate([perc, perc2])\n",
    "display(res1.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.sort_values('Lev Set Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# func and threshs defined previously\n",
    "\n",
    "perc = np.arange(0,1, 0.1)\n",
    "\n",
    "\n",
    "res2, cres2 = thres_analysis_unknown(2, names, func, tests)\n",
    "#display(res2.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cres2.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = np.arange(0,0.9, 0.1)\n",
    "perc2 = np.arange(0.9, 1, 0.05)\n",
    "perc = np.concatenate([perc, perc2])\n",
    "display(res2.describe(percentiles=perc).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.sort_values('Custom Lev Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cres1.to_pickle('cres1.pkl')\n",
    "cres2.to_pickle('cres2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein Set Ratio\n",
    "\n",
    "cres11 = cres1.describe().loc['mean':'mean',:]\n",
    "cres11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Levenshtein Ratio\n",
    "\n",
    "cres22 = cres2.describe().loc['mean':'mean',:]\n",
    "cres22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([cres22, cres11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([0.535, 0.586]))\n",
    "print(np.mean([0.514, 0.587]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earlier thresholds suggestions were kept as:\n",
    "- Levenshtein Set Ratio = **0.535** *(for name matching)*\n",
    "- Custom Levenshtein ratio = **0.514** *(for phoneme matching)*\n",
    "\n",
    "The thresholds using the False positives were chosen at 95%, with values being:\n",
    "- Levenshtein Set Ratio, *(for name matching)* = **0.586**\n",
    "- Custom Levenshtein ratio, *(for phoneme matching)* = **0.587**\n",
    "\n",
    "Therefore, taking average as :\n",
    "- Levenshtein Set Ratio, *(for name matching)* = **0.56**\n",
    "- Custom Levenshtein ratio, *(for phoneme matching)* = **0.55**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Finding best solution <a class=\"anchor\" id=\"find-solution\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is compared on all the test sets using the finalized metrics **Levenshtein Set Ratio & Custom Levenshtein Ratio** and using the corresponding thresholds of **0.56 & 0.55**. The different solutions are listed below:\n",
    "1. Using Levenshtein set ratio on the names directly ***(Traditional approach)***\n",
    "2. Using Levenshtein set ratio on the phonemes of the names\n",
    "3. Using custom Levenshtein ratio to measure similarity between the phonemes of the names\n",
    "4. Using BOTH Levenshtein set ratio on names AND custom Levenshtein ratio on phonemes of the names for comparision ***(Proposed approach 1)***\n",
    "5. Using EITHER Levenshtein set ratio Levenshtein set ratioon names OR custom Levenshtein ratio on phonemes of the names for comparision ***(Proposed approach 2)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Using True Positve names test set\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "funcs = [lev_setratio, \n",
    "         lev_setratio, \n",
    "         lev_ratio, \n",
    "         [lev_setratio, lev_ratio], \n",
    "         [lev_setratio, lev_ratio]]\n",
    "\n",
    "\n",
    "thresholds = [0.56, 0.56, 0.55, [0.56, 0.55], [0.56, 0.55]]\n",
    "\n",
    "final_results = []\n",
    "\n",
    "df = pd.DataFrame(columns={'Solution', 'Actual', 'Searched', 'Num_of_matches', 'Name_found', 'Time'})\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(len(tests[:-1])):\n",
    "    actual_name = tests[i][0]\n",
    "    display(names[names.Name.str.contains(actual_name)])\n",
    "    for j in range(len(tests[i][1])):\n",
    "        searched_name = tests[i][1][j]\n",
    "\n",
    "        for k in range(5):\n",
    "            res = solutions(k+1, names, funcs[k], thresholds[k], searched_name, actual_name, False)\n",
    "            if res is not None:\n",
    "                final_results.append(res)\n",
    "        \n",
    "        df2 = pd.DataFrame({\"Solution\": [val[0] for val in final_results], \n",
    "                            \"Actual\": actual_name, \n",
    "                            \"Searched\": searched_name, \n",
    "                            \"Num_of_matches\": [val[1].shape[0] for val in final_results],\n",
    "                            \"Name_found\": [val[2] for val in final_results], \n",
    "                            \"Time\": [val[3] for val in final_results]})\n",
    "        \n",
    "        df = pd.concat([df, df2], ignore_index=True)\n",
    "        \n",
    "        \n",
    "print(f'---- Total Execution Time: {time.time() - start_time} seconds ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Temp_save_data_w_Random.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 3000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Using False Positve names test set\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "funcs = [lev_setratio, \n",
    "         lev_setratio, \n",
    "         lev_ratio, \n",
    "         [lev_setratio, lev_ratio], \n",
    "         [lev_setratio, lev_ratio]]\n",
    "\n",
    "\n",
    "thresholds = [0.56, 0.56, 0.55, [0.56, 0.55], [0.56, 0.55]]\n",
    "\n",
    "final_results = []\n",
    "\n",
    "df = pd.DataFrame(columns={'Solution', 'Searched', 'Num_of_matches', 'Time'})\n",
    "\n",
    "start_time = time.time()\n",
    "for i in tests[-1][1]:\n",
    "\n",
    "    searched_name = i\n",
    "\n",
    "    for k in range(5):\n",
    "        res = solutions2(k+1, names, funcs[k], thresholds[k], searched_name, False)\n",
    "        if res is not None:\n",
    "            final_results.append(res)\n",
    "\n",
    "    df2 = pd.DataFrame({\"Solution\": [val[0] for val in final_results], \n",
    "                        \"Searched\": searched_name, \n",
    "                        \"Num_of_matches\": [val[1].shape[0] for val in final_results],\n",
    "                        \"Time\": [val[2] for val in final_results]})\n",
    "\n",
    "    df = pd.concat([df, df2], ignore_index=True)\n",
    "        \n",
    "        \n",
    "print(f'---- Total Execution Time: {time.time() - start_time} seconds ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Temp_save_false_w_Random.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generating Performance Plots <a class=\"anchor\" id=\"gen-plots\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Using True Positve names test set <a class=\"anchor\" id=\"sec_4_1\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Temp_save_data_w_Random.pkl')\n",
    "df.Num_of_matches = df.Num_of_matches.astype('int64')\n",
    "df.Name_found = df.Name_found.astype('bool')\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Solution']).mean().reset_index()\n",
    "df2['Name_found'] = df2['Name_found']*100\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df22 = df2[~df2.Solution.str.contains('Intermediate')]\n",
    "show_performance_plots(df2, 'Solution', [(0,40),(0,12000)], \"List of solutions\", (20,5))\n",
    "show_TP_perc_plot(df2, 'Solution', (80,105), (20,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Using False Positve names test set <a class=\"anchor\" id=\"sec_4_2\"></a>\n",
    " \n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Temp_save_false_w_Random.pkl')\n",
    "df.Num_of_matches = df.Num_of_matches.astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Solution']).mean().reset_index()\n",
    "#df2['Name_found'] = df2['Name_found']*100\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_performance_plots(df2, 'Solution', [(0,40),(0,12000)], \"List of solutions\", (20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Finding best solution for names without random names <a class=\"anchor\" id=\"alt-find-solution\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is compared on all the test sets using the finalized metrics **Levenshtein Set Ratio & Custom Levenshtein Ratio** and using the corresponding thresholds of **0.56 & 0.55**. The different solutions are listed below:\n",
    "\n",
    "1. Using Levenshtein set ratio on the names directly ***(Traditional approach)***\n",
    "2. Using Levenshtein set ratio on the phonemes of the names\n",
    "3. Using custom Levenshtein ratio to measure similarity between the phonemes of the names\n",
    "4. Using BOTH Levenshtein set ratio on names AND custom Levenshtein ratio on phonemes of the names for comparision ***(Proposed approach 1)***\n",
    "5. Using EITHER Levenshtein set ratio Levenshtein set ratioon names OR custom Levenshtein ratio on phonemes of the names for comparision ***(Proposed approach 2)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Loading data source and test set <a class=\"anchor\" id=\"sec_5_1\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_pickle('Final_Names_wo_Random.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [[\"Vladimir Nikolaevich Terentev\", [\"Vadimir Nikolevi Terente\", \n",
    "                                            \"Valdimi Terente\", \n",
    "                                            \"Baldimi Nikola Terete\", \n",
    "                                            \"Wadimi Terente\", \n",
    "                                            \"Baldimir Derend\"]], \n",
    "         [\"Andrey Alshevskih\", [\"andre alshveck\", \n",
    "                                \"andrew alshvek\", \n",
    "                                \"andy alshevsik\", \n",
    "                                \"andy alsevsikh\", \n",
    "                                \"Aandre Alshweshk\"]],\n",
    "         [\"Andrei Skoch\", [\"andrew skok\", \n",
    "                           \"andre skokh\", \n",
    "                           \"andrai skosh\", \n",
    "                           \"Aandre kock\", \n",
    "                           \"Andres kok\"]], \n",
    "         [\"Sheikh Aboud Rogo\", [\"Shake Abud rogo\", \n",
    "                                \"Sheik abod roguo\", \n",
    "                                \"about roguo\", \n",
    "                                \"shaikh rogo\", \n",
    "                                \"Shek Abed Rogo\"]], \n",
    "         [\"Mohammad Fayez Al-Barsha\", [\"Mohamad Fayis Barsa\", \n",
    "                                       \"Fayes Barhsa\", \n",
    "                                       \"Mohamed Al barsha\", \n",
    "                                       \"Moamad faes albasha\", \n",
    "                                       \"mohamad fayiz\"]], \n",
    "         [\"Wael Mohamad ABED AL RAHMAAN\", [\"Wel Mohammad ABID RAHMAN\", \n",
    "                                           \"Wael AL-HUSSEINI\", \n",
    "                                           \"Wel Huseni\", \n",
    "                                           \"Mohammad Rehman\", \n",
    "                                           \"Vial Abed\"]], \n",
    "         [\"Khaled Suleiman Fayez ABOU HASSAN\", [\"Khalid Sulayman Fayiz ABU HASAN\", \n",
    "                                                \"Khaled ABU HASSAN\", \n",
    "                                                \"Kahleed Asan\", \n",
    "                                                \"Kohlid Faye Hasin\", \n",
    "                                                \"Galed Hassan\"]], \n",
    "         [\"David Amos Mazengo\", [\"Dave Masengo\", \n",
    "                                 \"Daveid Mos Masingo\", \n",
    "                                 \"Dave Masego\", \n",
    "                                 \"Daive Masego\", \n",
    "                                 \"Davie Mos Masigo\"]], \n",
    "         [\"Anas Tals\", [\"Annas Taals\", \n",
    "                        \"Unus Tuls\", \n",
    "                        \"Aanas Daals\", \n",
    "                        \"Aanas Thaals\", \n",
    "                        \"Aunaas Dhals\"]], \n",
    "         [\"DUMMY DATA\", [\"Antonio Hodge\", \n",
    "                         \"Charles Madriz\", \n",
    "                         \"Aleh Vladimir Aziz\", \n",
    "                         \"Luke Powell\", \n",
    "                         \"Anthony Gammell\", \n",
    "                         \"Carlos Vilches\", \n",
    "                         \"Mike Felix\", \n",
    "                         \"Rodrigue Patterson\", \n",
    "                         \"Anya D'Souza\", \n",
    "                         \"Joshua Matthers\", \n",
    "                         \"Michael Myers\", \n",
    "                         \"Owen Price\", \n",
    "                         \"Christopher Peres\", \n",
    "                         \"Mark Gibney\", \n",
    "                         \"Andrew Roy\", \n",
    "                         \"Jared Miller\", \n",
    "                         \"Scott Romero\", \n",
    "                         \"Alex Owen\", \n",
    "                         \"Steve Leben\", \n",
    "                         \"Kirk Jensen\", \n",
    "                         \"Kevin Berry\", \n",
    "                         \"Mike King\", \n",
    "                         \"Mark Bruno\", \n",
    "                         \"Tony Hayes\", \n",
    "                         \"Kevin Sanchez\", \n",
    "                         \"Bill Miller\", \n",
    "                         \"Bob Turner\", \n",
    "                         \"James Wilson\", \n",
    "                         \"Matt Smith\", \n",
    "                         \"Ted Blair\", \n",
    "                         \"Eric Dalton\", \n",
    "                         \"Lynn Davis\", \n",
    "                         \"Dennis Joseph\", \n",
    "                         \"Andrew Ford\", \n",
    "                         \"Douglas Williams\", \n",
    "                         \"Lee Davidson\", \n",
    "                         \"Henry Cohen\", \n",
    "                         \"Carl Jacobs\", \n",
    "                         \"Terry Martinez\", \n",
    "                         \"Joshua Davis\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tests:\n",
    "    display(names[names.Name.str.contains(t[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Using True Positve names test set <a class=\"anchor\" id=\"sec_5_2\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "funcs = [lev_setratio, \n",
    "         lev_setratio, \n",
    "         lev_ratio, \n",
    "         [lev_setratio, lev_ratio], \n",
    "         [lev_setratio, lev_ratio]]\n",
    "\n",
    "\n",
    "thresholds = [0.56, 0.56, 0.55, [0.56, 0.55], [0.56, 0.55]]\n",
    "\n",
    "final_results = []\n",
    "\n",
    "df = pd.DataFrame(columns={'Solution', 'Actual', 'Searched', 'Num_of_matches', 'Name_found', 'Time'})\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(len(tests[:-1])):\n",
    "    actual_name = tests[i][0]\n",
    "    display(names[names.Name.str.contains(actual_name)])\n",
    "    for j in range(len(tests[i][1])):\n",
    "        searched_name = tests[i][1][j]\n",
    "\n",
    "        for k in range(5):\n",
    "            res = solutions(k+1, names, funcs[k], thresholds[k], searched_name, actual_name, False)\n",
    "            if res is not None:\n",
    "                final_results.append(res)\n",
    "        \n",
    "        df2 = pd.DataFrame({\"Solution\": [val[0] for val in final_results], \n",
    "                            \"Actual\": actual_name, \n",
    "                            \"Searched\": searched_name, \n",
    "                            \"Num_of_matches\": [val[1].shape[0] for val in final_results],\n",
    "                            \"Name_found\": [val[2] for val in final_results], \n",
    "                            \"Time\": [val[3] for val in final_results]})\n",
    "        \n",
    "        df = pd.concat([df, df2], ignore_index=True)\n",
    "        \n",
    "        \n",
    "print(f'---- Total Execution Time: {time.time() - start_time} seconds ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Temp_save_data_wo_Random.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Using False Positve names test set <a class=\"anchor\" id=\"sec_5_3\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [lev_setratio, \n",
    "         lev_setratio, \n",
    "         lev_ratio, \n",
    "         [lev_setratio, lev_ratio], \n",
    "         [lev_setratio, lev_ratio]]\n",
    "\n",
    "\n",
    "thresholds = [0.56, 0.56, 0.55, [0.56, 0.55], [0.56, 0.55]]\n",
    "\n",
    "final_results = []\n",
    "\n",
    "df = pd.DataFrame(columns={'Solution', 'Searched', 'Num_of_matches', 'Time'})\n",
    "\n",
    "start_time = time.time()\n",
    "for i in tests[-1][1]:\n",
    "\n",
    "    searched_name = i\n",
    "\n",
    "    for k in range(5):\n",
    "        res = solutions2(k+1, names, funcs[k], thresholds[k], searched_name, False)\n",
    "        if res is not None:\n",
    "            final_results.append(res)\n",
    "\n",
    "    df2 = pd.DataFrame({\"Solution\": [val[0] for val in final_results], \n",
    "                        \"Searched\": searched_name, \n",
    "                        \"Num_of_matches\": [val[1].shape[0] for val in final_results],\n",
    "                        \"Time\": [val[2] for val in final_results]})\n",
    "\n",
    "    df = pd.concat([df, df2], ignore_index=True)\n",
    "        \n",
    "        \n",
    "print(f'---- Total Execution Time: {time.time() - start_time} seconds ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Temp_save_false_wo_Random.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Generating Performance Plots <a class=\"anchor\" id=\"sec_5_4\"></a>\n",
    "\n",
    "Go to [Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Using True Positve names test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Temp_save_data_wo_Random.pkl')\n",
    "df.Num_of_matches = df.Num_of_matches.astype('int64')\n",
    "df.Name_found = df.Name_found.astype('bool')\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Solution']).mean().reset_index()\n",
    "df2['Name_found'] = df2['Name_found']*100\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df22 = df2[~df2.Solution.str.contains('Intermediate')]\n",
    "show_performance_plots(df2, 'Solution', [(0,11),(0,3000)], \"List of solutions\", (20,5))\n",
    "show_TP_perc_plot(df2, 'Solution', (80,105), (20,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Using False Positve names test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Temp_save_false_wo_Random.pkl')\n",
    "df.Num_of_matches = df.Num_of_matches.astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Solution']).mean().reset_index()\n",
    "#df2['Name_found'] = df2['Name_found']*100\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_performance_plots(df2, 'Solution', [(0,7),(0,2500)], \"List of solutions\", (20,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
